{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2af2e4f-a43a-4dc8-8090-b2f811884a15",
   "metadata": {},
   "source": [
    "# Background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a241bc03-d693-45f1-8135-adcc77b5368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wsi_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcd5fc-c8cb-4183-8155-593176904e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_background.vsi_background_subtract(vsi_path = 'Images/02_02_20250422_100017.vsi', \n",
    "                                        raw_folder = 'Images_raw_2',\n",
    "                                        output_ometiff = 'pyramid_output_2.ome.tiff',\n",
    "                                        overwrite=False,\n",
    "                                        load_into_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "058ad6f4-410a-4245-a168-f3b932e2dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 11 pyramid arrays in: Images_raw_regions_brain/region_001/0/\n",
      "üìè Level 0 shape: (1, 3, 1, 17358, 27903), dtype: >u2\n",
      "üê¢ Using Dask (lazy, more memory efficient)...\n",
      "üîß rolling_ball params={'method': 'rolling_ball', 'sigma_px': 100}\n",
      "üíæ Writing Dask level 0\n",
      "üíæ Writing Dask level 1\n",
      "üíæ Writing Dask level 2\n",
      "üíæ Writing Dask level 3\n",
      "üíæ Writing Dask level 4\n",
      "üíæ Writing Dask level 5\n",
      "üíæ Writing Dask level 6\n",
      "üíæ Writing Dask level 7\n",
      "üíæ Writing Dask level 8\n",
      "üíæ Writing Dask level 9\n",
      "üíæ Writing Dask level 10\n",
      "‚úÖ Zarr pyramid update complete.\n"
     ]
    }
   ],
   "source": [
    "wsi_background.save_modified_zarr_pyramid(zarr_path = \"Images_raw_regions_brain/region_001\", \n",
    "                                          zarr_level=\"0\", \n",
    "                                          methods=[{\"method\": \"rolling_ball\", \"sigma_px\": 100}], \n",
    "                                          load_into_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ab927-0ac8-48e9-9106-e9337fdc2289",
   "metadata": {},
   "source": [
    "# Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9909aa9-679c-41a5-8c86-2f43c7af3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari_tile_inspector_safe(raw_dask, chunk_size=(1024, 1024), channel_names=[\"DAPI\", \"FITC\"],\n",
    "   channel_colors=[\"blue\",\"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbe59e-eeb7-4a4a-a19b-97a2e51ca1b6",
   "metadata": {},
   "source": [
    "# Slide cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45cb4454-2ef1-4515-ad27-fd16edb37f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wsi_background' from 'D:\\\\Programming\\\\whole_slide_analysis\\\\wsi_background.py'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wsi_background\n",
    "import importlib\n",
    "importlib.reload(wsi_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0c174eb-43a5-42d3-a67c-05fd1df07d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1df5d97a-b66a-4751-ae6b-741e61e98a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = zarr.open(\"Images_raw_2\", mode='r+')[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d956bc1d-8f91-4159-8125-8311bac91794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in store.array_keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e3c0ed0-f70c-49e7-8159-c9f70e3bcb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 55.13 GiB </td>\n",
       "                        <td> 1.00 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 3, 1, 66523, 148307) </td>\n",
       "                        <td> (1, 1, 1, 1024, 512) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 56550 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> >u2 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"374\" height=\"118\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"25\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"16\" y2=\"25\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"45.412617\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.412617,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"109\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"1\" x2=\"109\" y2=\"16\" />\n",
       "  <line x1=\"95\" y1=\"3\" x2=\"109\" y2=\"18\" />\n",
       "  <line x1=\"95\" y1=\"4\" x2=\"109\" y2=\"19\" />\n",
       "  <line x1=\"95\" y1=\"6\" x2=\"109\" y2=\"21\" />\n",
       "  <line x1=\"95\" y1=\"8\" x2=\"109\" y2=\"23\" />\n",
       "  <line x1=\"95\" y1=\"9\" x2=\"109\" y2=\"24\" />\n",
       "  <line x1=\"95\" y1=\"11\" x2=\"109\" y2=\"26\" />\n",
       "  <line x1=\"95\" y1=\"13\" x2=\"109\" y2=\"28\" />\n",
       "  <line x1=\"95\" y1=\"14\" x2=\"109\" y2=\"29\" />\n",
       "  <line x1=\"95\" y1=\"16\" x2=\"109\" y2=\"31\" />\n",
       "  <line x1=\"95\" y1=\"18\" x2=\"109\" y2=\"33\" />\n",
       "  <line x1=\"95\" y1=\"19\" x2=\"109\" y2=\"34\" />\n",
       "  <line x1=\"95\" y1=\"21\" x2=\"109\" y2=\"36\" />\n",
       "  <line x1=\"95\" y1=\"23\" x2=\"109\" y2=\"38\" />\n",
       "  <line x1=\"95\" y1=\"24\" x2=\"109\" y2=\"39\" />\n",
       "  <line x1=\"95\" y1=\"26\" x2=\"109\" y2=\"41\" />\n",
       "  <line x1=\"95\" y1=\"28\" x2=\"109\" y2=\"43\" />\n",
       "  <line x1=\"95\" y1=\"29\" x2=\"109\" y2=\"44\" />\n",
       "  <line x1=\"95\" y1=\"31\" x2=\"109\" y2=\"46\" />\n",
       "  <line x1=\"95\" y1=\"33\" x2=\"109\" y2=\"48\" />\n",
       "  <line x1=\"95\" y1=\"34\" x2=\"109\" y2=\"49\" />\n",
       "  <line x1=\"95\" y1=\"36\" x2=\"109\" y2=\"51\" />\n",
       "  <line x1=\"95\" y1=\"38\" x2=\"109\" y2=\"53\" />\n",
       "  <line x1=\"95\" y1=\"39\" x2=\"109\" y2=\"54\" />\n",
       "  <line x1=\"95\" y1=\"41\" x2=\"109\" y2=\"56\" />\n",
       "  <line x1=\"95\" y1=\"43\" x2=\"109\" y2=\"58\" />\n",
       "  <line x1=\"95\" y1=\"44\" x2=\"109\" y2=\"59\" />\n",
       "  <line x1=\"95\" y1=\"46\" x2=\"109\" y2=\"61\" />\n",
       "  <line x1=\"95\" y1=\"48\" x2=\"109\" y2=\"63\" />\n",
       "  <line x1=\"95\" y1=\"49\" x2=\"109\" y2=\"64\" />\n",
       "  <line x1=\"95\" y1=\"51\" x2=\"109\" y2=\"66\" />\n",
       "  <line x1=\"95\" y1=\"53\" x2=\"109\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"109\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 109.9485979497544,14.948597949754403 109.9485979497544,68.77451311222144 95.0,53.82591516246704\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"229\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"109\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"98\" y1=\"0\" x2=\"113\" y2=\"14\" />\n",
       "  <line x1=\"102\" y1=\"0\" x2=\"117\" y2=\"14\" />\n",
       "  <line x1=\"106\" y1=\"0\" x2=\"121\" y2=\"14\" />\n",
       "  <line x1=\"109\" y1=\"0\" x2=\"124\" y2=\"14\" />\n",
       "  <line x1=\"113\" y1=\"0\" x2=\"128\" y2=\"14\" />\n",
       "  <line x1=\"117\" y1=\"0\" x2=\"132\" y2=\"14\" />\n",
       "  <line x1=\"121\" y1=\"0\" x2=\"136\" y2=\"14\" />\n",
       "  <line x1=\"124\" y1=\"0\" x2=\"139\" y2=\"14\" />\n",
       "  <line x1=\"128\" y1=\"0\" x2=\"143\" y2=\"14\" />\n",
       "  <line x1=\"132\" y1=\"0\" x2=\"147\" y2=\"14\" />\n",
       "  <line x1=\"136\" y1=\"0\" x2=\"150\" y2=\"14\" />\n",
       "  <line x1=\"139\" y1=\"0\" x2=\"154\" y2=\"14\" />\n",
       "  <line x1=\"143\" y1=\"0\" x2=\"158\" y2=\"14\" />\n",
       "  <line x1=\"147\" y1=\"0\" x2=\"162\" y2=\"14\" />\n",
       "  <line x1=\"150\" y1=\"0\" x2=\"165\" y2=\"14\" />\n",
       "  <line x1=\"155\" y1=\"0\" x2=\"170\" y2=\"14\" />\n",
       "  <line x1=\"158\" y1=\"0\" x2=\"173\" y2=\"14\" />\n",
       "  <line x1=\"162\" y1=\"0\" x2=\"177\" y2=\"14\" />\n",
       "  <line x1=\"166\" y1=\"0\" x2=\"181\" y2=\"14\" />\n",
       "  <line x1=\"169\" y1=\"0\" x2=\"184\" y2=\"14\" />\n",
       "  <line x1=\"173\" y1=\"0\" x2=\"188\" y2=\"14\" />\n",
       "  <line x1=\"177\" y1=\"0\" x2=\"192\" y2=\"14\" />\n",
       "  <line x1=\"181\" y1=\"0\" x2=\"196\" y2=\"14\" />\n",
       "  <line x1=\"184\" y1=\"0\" x2=\"199\" y2=\"14\" />\n",
       "  <line x1=\"188\" y1=\"0\" x2=\"203\" y2=\"14\" />\n",
       "  <line x1=\"192\" y1=\"0\" x2=\"207\" y2=\"14\" />\n",
       "  <line x1=\"196\" y1=\"0\" x2=\"211\" y2=\"14\" />\n",
       "  <line x1=\"199\" y1=\"0\" x2=\"214\" y2=\"14\" />\n",
       "  <line x1=\"203\" y1=\"0\" x2=\"218\" y2=\"14\" />\n",
       "  <line x1=\"207\" y1=\"0\" x2=\"222\" y2=\"14\" />\n",
       "  <line x1=\"210\" y1=\"0\" x2=\"225\" y2=\"14\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"229\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 215.0,0.0 229.9485979497544,14.948597949754403 109.9485979497544,14.948597949754403\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"229\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"109\" y1=\"16\" x2=\"229\" y2=\"16\" />\n",
       "  <line x1=\"109\" y1=\"18\" x2=\"229\" y2=\"18\" />\n",
       "  <line x1=\"109\" y1=\"19\" x2=\"229\" y2=\"19\" />\n",
       "  <line x1=\"109\" y1=\"21\" x2=\"229\" y2=\"21\" />\n",
       "  <line x1=\"109\" y1=\"23\" x2=\"229\" y2=\"23\" />\n",
       "  <line x1=\"109\" y1=\"24\" x2=\"229\" y2=\"24\" />\n",
       "  <line x1=\"109\" y1=\"26\" x2=\"229\" y2=\"26\" />\n",
       "  <line x1=\"109\" y1=\"28\" x2=\"229\" y2=\"28\" />\n",
       "  <line x1=\"109\" y1=\"29\" x2=\"229\" y2=\"29\" />\n",
       "  <line x1=\"109\" y1=\"31\" x2=\"229\" y2=\"31\" />\n",
       "  <line x1=\"109\" y1=\"33\" x2=\"229\" y2=\"33\" />\n",
       "  <line x1=\"109\" y1=\"34\" x2=\"229\" y2=\"34\" />\n",
       "  <line x1=\"109\" y1=\"36\" x2=\"229\" y2=\"36\" />\n",
       "  <line x1=\"109\" y1=\"38\" x2=\"229\" y2=\"38\" />\n",
       "  <line x1=\"109\" y1=\"39\" x2=\"229\" y2=\"39\" />\n",
       "  <line x1=\"109\" y1=\"41\" x2=\"229\" y2=\"41\" />\n",
       "  <line x1=\"109\" y1=\"43\" x2=\"229\" y2=\"43\" />\n",
       "  <line x1=\"109\" y1=\"44\" x2=\"229\" y2=\"44\" />\n",
       "  <line x1=\"109\" y1=\"46\" x2=\"229\" y2=\"46\" />\n",
       "  <line x1=\"109\" y1=\"48\" x2=\"229\" y2=\"48\" />\n",
       "  <line x1=\"109\" y1=\"49\" x2=\"229\" y2=\"49\" />\n",
       "  <line x1=\"109\" y1=\"51\" x2=\"229\" y2=\"51\" />\n",
       "  <line x1=\"109\" y1=\"53\" x2=\"229\" y2=\"53\" />\n",
       "  <line x1=\"109\" y1=\"54\" x2=\"229\" y2=\"54\" />\n",
       "  <line x1=\"109\" y1=\"56\" x2=\"229\" y2=\"56\" />\n",
       "  <line x1=\"109\" y1=\"58\" x2=\"229\" y2=\"58\" />\n",
       "  <line x1=\"109\" y1=\"59\" x2=\"229\" y2=\"59\" />\n",
       "  <line x1=\"109\" y1=\"61\" x2=\"229\" y2=\"61\" />\n",
       "  <line x1=\"109\" y1=\"63\" x2=\"229\" y2=\"63\" />\n",
       "  <line x1=\"109\" y1=\"64\" x2=\"229\" y2=\"64\" />\n",
       "  <line x1=\"109\" y1=\"66\" x2=\"229\" y2=\"66\" />\n",
       "  <line x1=\"109\" y1=\"68\" x2=\"229\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"109\" y1=\"14\" x2=\"109\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"113\" y1=\"14\" x2=\"113\" y2=\"68\" />\n",
       "  <line x1=\"117\" y1=\"14\" x2=\"117\" y2=\"68\" />\n",
       "  <line x1=\"121\" y1=\"14\" x2=\"121\" y2=\"68\" />\n",
       "  <line x1=\"124\" y1=\"14\" x2=\"124\" y2=\"68\" />\n",
       "  <line x1=\"128\" y1=\"14\" x2=\"128\" y2=\"68\" />\n",
       "  <line x1=\"132\" y1=\"14\" x2=\"132\" y2=\"68\" />\n",
       "  <line x1=\"136\" y1=\"14\" x2=\"136\" y2=\"68\" />\n",
       "  <line x1=\"139\" y1=\"14\" x2=\"139\" y2=\"68\" />\n",
       "  <line x1=\"143\" y1=\"14\" x2=\"143\" y2=\"68\" />\n",
       "  <line x1=\"147\" y1=\"14\" x2=\"147\" y2=\"68\" />\n",
       "  <line x1=\"150\" y1=\"14\" x2=\"150\" y2=\"68\" />\n",
       "  <line x1=\"154\" y1=\"14\" x2=\"154\" y2=\"68\" />\n",
       "  <line x1=\"158\" y1=\"14\" x2=\"158\" y2=\"68\" />\n",
       "  <line x1=\"162\" y1=\"14\" x2=\"162\" y2=\"68\" />\n",
       "  <line x1=\"165\" y1=\"14\" x2=\"165\" y2=\"68\" />\n",
       "  <line x1=\"170\" y1=\"14\" x2=\"170\" y2=\"68\" />\n",
       "  <line x1=\"173\" y1=\"14\" x2=\"173\" y2=\"68\" />\n",
       "  <line x1=\"177\" y1=\"14\" x2=\"177\" y2=\"68\" />\n",
       "  <line x1=\"181\" y1=\"14\" x2=\"181\" y2=\"68\" />\n",
       "  <line x1=\"184\" y1=\"14\" x2=\"184\" y2=\"68\" />\n",
       "  <line x1=\"188\" y1=\"14\" x2=\"188\" y2=\"68\" />\n",
       "  <line x1=\"192\" y1=\"14\" x2=\"192\" y2=\"68\" />\n",
       "  <line x1=\"196\" y1=\"14\" x2=\"196\" y2=\"68\" />\n",
       "  <line x1=\"199\" y1=\"14\" x2=\"199\" y2=\"68\" />\n",
       "  <line x1=\"203\" y1=\"14\" x2=\"203\" y2=\"68\" />\n",
       "  <line x1=\"207\" y1=\"14\" x2=\"207\" y2=\"68\" />\n",
       "  <line x1=\"211\" y1=\"14\" x2=\"211\" y2=\"68\" />\n",
       "  <line x1=\"214\" y1=\"14\" x2=\"214\" y2=\"68\" />\n",
       "  <line x1=\"218\" y1=\"14\" x2=\"218\" y2=\"68\" />\n",
       "  <line x1=\"222\" y1=\"14\" x2=\"222\" y2=\"68\" />\n",
       "  <line x1=\"225\" y1=\"14\" x2=\"225\" y2=\"68\" />\n",
       "  <line x1=\"229\" y1=\"14\" x2=\"229\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"109.9485979497544,14.948597949754403 229.9485979497544,14.948597949754403 229.9485979497544,68.77451311222144 109.9485979497544,68.77451311222144\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"169.948598\" y=\"88.774513\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >148307</text>\n",
       "  <text x=\"249.948598\" y=\"41.861556\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,249.948598,41.861556)\">66523</text>\n",
       "  <text x=\"92.474299\" y=\"81.300214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,92.474299,81.300214)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(1, 3, 1, 66523, 148307), dtype=>u2, chunksize=(1, 1, 1, 1024, 512), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = zarr.open(\"Images_raw_2\", mode='r+')[\"0\"][\"0\"]\n",
    "raw_dask = da.from_zarr(store)\n",
    "raw_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "649d0b43-83d2-4707-8e83-52b8518230be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Annotation viewer launched for Images_raw, saving to Images_raw_regions_2\n"
     ]
    }
   ],
   "source": [
    "viewer = wsi_background.launch_annotation_viewer(zarr_path=\"Images_raw\",\n",
    "                                                 output_root='Images_raw_regions_2',\n",
    "                                                 zarr_level=\"0\", \n",
    "                                                 display_level=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "293c032a-8dac-4ca8-8e31-91e3e8b940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Open and clean metadata\n",
    "with open(os.path.join(\"Images_raw_regions\",\"region_001\", \"OME\", \"METADATA.ome.xml\"), encoding='utf-8') as f:\n",
    "    xml_text = f.read()\n",
    "\n",
    "xml_text = xml_text.replace(\"√Ç¬µm\", \"¬µm\")\n",
    "\n",
    "# Now parse with ome-types\n",
    "from ome_types import from_xml\n",
    "ome = from_xml(xml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b74af8-bcdd-40c1-b01d-09fc03ec128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ome.structured_annotations.xml_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a8b8aec8-cc62-49a9-b8eb-4581417336a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Image(\n",
       "    id='Image:2',\n",
       "    name='20x_KSS FITC, KSS Cy3, KSS Cy5_01',\n",
       "    acquisition_date='2025-04-22T08:25:01',\n",
       "    instrument_ref={'id': 'Instrument:0'},\n",
       "    objective_settings={'id': 'Objective:0:2', 'refractive_index': 1.0},\n",
       "    pixels={'channels': [{'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:0', 'name': 'KSS FITC', 'samples_per_pixel': 1, 'emission_wavelength': 518.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:1', 'name': 'KSS Cy3', 'samples_per_pixel': 1, 'emission_wavelength': 565.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:2', 'name': 'KSS Cy5', 'samples_per_pixel': 1, 'emission_wavelength': 670.0}], 'metadata_only': {}, 'planes': [{'the_z': 0, 'the_t': 0, 'the_c': 0, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 1, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 2, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}], 'id': 'Pixels:2', 'dimension_order': <Pixels_DimensionOrder.XYZCT: 'XYZCT'>, 'type': <PixelType.UINT16: 'uint16'>, 'significant_bits': 16, 'interleaved': False, 'big_endian': True, 'size_x': 148307, 'size_y': 66523, 'size_z': 1, 'size_c': 3, 'size_t': 1, 'physical_size_x': 0.3250015171232646, 'physical_size_y': 0.3250016448125979},\n",
       " )]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ome.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58b85f39-9f1b-4305-b5e2-4358879e20cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(\n",
       "   id='Image:2',\n",
       "   name='20x_KSS FITC, KSS Cy3, KSS Cy5_01',\n",
       "   acquisition_date='2025-04-22T08:25:01',\n",
       "   instrument_ref={'id': 'Instrument:0'},\n",
       "   objective_settings={'id': 'Objective:0:2', 'refractive_index': 1.0},\n",
       "   pixels={'channels': [{'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:0', 'name': 'KSS FITC', 'samples_per_pixel': 1, 'emission_wavelength': 518.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:1', 'name': 'KSS Cy3', 'samples_per_pixel': 1, 'emission_wavelength': 565.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:2', 'name': 'KSS Cy5', 'samples_per_pixel': 1, 'emission_wavelength': 670.0}], 'metadata_only': {}, 'planes': [{'the_z': 0, 'the_t': 0, 'the_c': 0, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 1, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 2, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}], 'id': 'Pixels:2', 'dimension_order': <Pixels_DimensionOrder.XYZCT: 'XYZCT'>, 'type': <PixelType.UINT16: 'uint16'>, 'significant_bits': 16, 'interleaved': False, 'big_endian': True, 'size_x': 148307, 'size_y': 66523, 'size_z': 1, 'size_c': 3, 'size_t': 1, 'physical_size_x': 0.3250015171232646, 'physical_size_y': 0.3250016448125979},\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ome.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0506a777-972a-4da8-84b3-d56254a4e92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(\n",
       "   id='Image:2',\n",
       "   name='20x_KSS FITC, KSS Cy3, KSS Cy5_01',\n",
       "   acquisition_date='2025-04-22T08:25:01',\n",
       "   instrument_ref={'id': 'Instrument:0'},\n",
       "   objective_settings={'id': 'Objective:0:2', 'refractive_index': 1.0},\n",
       "   pixels={'channels': [{'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:0', 'name': 'KSS FITC', 'samples_per_pixel': 1, 'emission_wavelength': 518.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:1', 'name': 'KSS Cy3', 'samples_per_pixel': 1, 'emission_wavelength': 565.0}, {'detector_settings': {'id': 'Detector:0:2', 'binning': <Binning.ONEBYONE: '1x1'>}, 'light_path': {}, 'id': 'Channel:2:2', 'name': 'KSS Cy5', 'samples_per_pixel': 1, 'emission_wavelength': 670.0}], 'metadata_only': {}, 'planes': [{'the_z': 0, 'the_t': 0, 'the_c': 0, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 1, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}, {'the_z': 0, 'the_t': 0, 'the_c': 2, 'exposure_time': 0.02, 'position_x': 20650.0, 'position_x_unit': <UnitsLength.MICROMETER: '¬µm'>, 'position_y': 3188.7864931410486, 'position_y_unit': <UnitsLength.MICROMETER: '¬µm'>}], 'id': 'Pixels:2', 'dimension_order': <Pixels_DimensionOrder.XYZCT: 'XYZCT'>, 'type': <PixelType.UINT16: 'uint16'>, 'significant_bits': 16, 'interleaved': False, 'big_endian': True, 'size_x': 148307, 'size_y': 66523, 'size_z': 1, 'size_c': 3, 'size_t': 1, 'physical_size_x': 0.3250015171232646, 'physical_size_y': 0.3250016448125979},\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ome.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dee8c41c-fb7d-4692-bd1f-c9af762ed37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instrument(\n",
       "    id='Instrument:0',\n",
       "    detectors=[<3 field_type>],\n",
       "    objectives=[<3 field_type>],\n",
       " )]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ome.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ff1084-6fe5-4b46-9566-5829d4979907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ome_zarr.format as ozf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4062eb2f-a1b8-4312-837a-e9e877d16d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_tree' from 'ome_zarr.format' (C:\\Anaconda3\\envs\\sbt\\Lib\\site-packages\\ome_zarr\\format.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mome_zarr\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m write_tree\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'write_tree' from 'ome_zarr.format' (C:\\Anaconda3\\envs\\sbt\\Lib\\site-packages\\ome_zarr\\format.py)"
     ]
    }
   ],
   "source": [
    "from ome_zarr.format import write_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "54da36af-5101-4757-8601-b9a91fcca3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 12 pyramid levels with chunk size (1, 1, 1, 1024, 1024)\n",
      "üîç Found 4 region files.\n",
      "‚úÇÔ∏è Cropping region: region_001 ‚Üí Y: 33895-48208, X: 55629-69126\n",
      "üìÅ Copied OME/ metadata folder\n",
      "üìÑ Copied root-level .zattrs\n",
      "üìÑ Copied root-level .zgroup\n",
      "üìÑ Copied 0/ level .zattrs\n",
      "üìÑ Copied 0/ level .zgroup\n",
      "üìÑ Updated OME-XML dimensions in: Images_raw_regions_2\\region_001\\OME\\METADATA.ome.xml\n",
      "‚úÖ Saved region to: Images_raw_regions_2\\region_001\n",
      "‚úÇÔ∏è Cropping region: region_002 ‚Üí Y: 22271-27122, X: 16387-20709\n",
      "üìÅ Copied OME/ metadata folder\n",
      "üìÑ Copied root-level .zattrs\n",
      "üìÑ Copied root-level .zgroup\n",
      "üìÑ Copied 0/ level .zattrs\n",
      "üìÑ Copied 0/ level .zgroup\n",
      "üìÑ Updated OME-XML dimensions in: Images_raw_regions_2\\region_002\\OME\\METADATA.ome.xml\n",
      "‚úÖ Saved region to: Images_raw_regions_2\\region_002\n",
      "‚úÇÔ∏è Cropping region: region_003 ‚Üí Y: 14586-18908, X: 66437-70759\n",
      "üìÅ Copied OME/ metadata folder\n",
      "üìÑ Copied root-level .zattrs\n",
      "üìÑ Copied root-level .zgroup\n",
      "üìÑ Copied 0/ level .zattrs\n",
      "üìÑ Copied 0/ level .zgroup\n",
      "üìÑ Updated OME-XML dimensions in: Images_raw_regions_2\\region_003\\OME\\METADATA.ome.xml\n",
      "‚úÖ Saved region to: Images_raw_regions_2\\region_003\n",
      "‚úÇÔ∏è Cropping region: region_004 ‚Üí Y: 44510-46095, X: 9374-11055\n",
      "üìÅ Copied OME/ metadata folder\n",
      "üìÑ Copied root-level .zattrs\n",
      "üìÑ Copied root-level .zgroup\n",
      "üìÑ Copied 0/ level .zattrs\n",
      "üìÑ Copied 0/ level .zgroup\n",
      "üìÑ Updated OME-XML dimensions in: Images_raw_regions_2\\region_004\\OME\\METADATA.ome.xml\n",
      "‚úÖ Saved region to: Images_raw_regions_2\\region_004\n"
     ]
    }
   ],
   "source": [
    "wsi_background.process_saved_regions(zarr_path=\"Images_raw\", \n",
    "                      region_dir='Images_raw_regions_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78596f6c-45aa-4fb8-928f-3934656a3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.reader import Reader\n",
    "from ome_zarr.writer import write_multiscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "495cada4-2e0d-42de-a01e-c1a9fe923feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the root of the OME-Zarr\n",
    "url = parse_url('Images_raw_2', mode=\"r+\").store\n",
    "\n",
    "# Pass the store to Reader\n",
    "reader = Reader(parse_url(url))\n",
    "nodes = list(reader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "603f2201-3281-426c-ae23-b2961f3070ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Reader.descend at 0x00000166224D1D40>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.descend(node=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071acb3-95a9-4318-b2bd-94b81a730037",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exported to module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917bca4-fdb3-4419-8ea6-e563390bf1e6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b95443-17e1-4cc5-a395-0a73f6f85f6a",
   "metadata": {},
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from skimage.transform import downscale_local_mean\n",
    "from ome_types import from_xml\n",
    "import subprocess\n",
    "import zarr\n",
    "from dask_image.ndfilters import gaussian_filter, median_filter\n",
    "from scipy.ndimage import grey_opening\n",
    "from scipy import ndimage\n",
    "from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "from skimage.transform import downscale_local_mean\n",
    "import numpy as np\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import random\n",
    "from magicgui import magicgui, widgets\n",
    "from skimage.io import imsave\n",
    "from napari.utils.notifications import show_info, show_warning, show_error\n",
    "from qtpy.QtCore import QTimer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f2140-f7be-43d5-bd54-6e839151e141",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e9809-a691-4aeb-9f49-a4bd7e2f56a1",
   "metadata": {},
   "source": [
    "def run_commandline(cmd: str, verbose: int = 0, return_readout = False, print_command=False):\n",
    "    '''\n",
    "    Wrapper to run command line (ie. java tools\n",
    "    '''\n",
    "    \n",
    "    if print_command: print(cmd)\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    \n",
    "    if return_readout: readout = []\n",
    "\n",
    "    if verbose == 0:\n",
    "        # capture the output silently when verbose is disabled\n",
    "        result = sp.run(cmd, shell=True, env=env, capture_output=True, text=True)\n",
    "\n",
    "        # check if the process failed\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"Command failed with error: {result.stderr}\")\n",
    "\n",
    "    else:\n",
    "        # stream output in real-time if verbose is enabled\n",
    "        process = sp.Popen(cmd, shell=True, env=env, stdout=sp.PIPE, stderr=sp.PIPE, text=True)\n",
    "\n",
    "        # stream stdout in real-time\n",
    "        for stdout_line in iter(process.stdout.readline, \"\"):\n",
    "            logging.info(stdout_line.strip())  # Log each line of output\n",
    "            \n",
    "            if return_readout:\n",
    "                readout.append(stdout_line.strip())\n",
    "            else:\n",
    "                print(stdout_line.strip())\n",
    "        \n",
    "        process.stdout.close()\n",
    "\n",
    "        # wait for process to finish\n",
    "        process.wait()\n",
    "\n",
    "        # check if the process failed\n",
    "        if process.returncode != 0:\n",
    "            stderr_output = process.stderr.read().strip()\n",
    "            process.stderr.close()\n",
    "            raise RuntimeError(f\"Command failed with error: {stderr_output}\")\n",
    "\n",
    "        process.stderr.close()\n",
    "    \n",
    "    if return_readout:\n",
    "        return readout\n",
    "\n",
    "\n",
    "def parse_showinf_series_metadata(log_lines, series_number):\n",
    "    series_data = {}\n",
    "    current_series = None\n",
    "    series_block = []\n",
    "\n",
    "    # Preprocess and segment the input into series blocks\n",
    "    for line in log_lines:\n",
    "        match = re.match(r\"Series #(\\d+) :\", line)\n",
    "        if match:\n",
    "            if current_series is not None:\n",
    "                series_data[current_series] = series_block\n",
    "            current_series = int(match.group(1))\n",
    "            series_block = []\n",
    "        elif current_series is not None:\n",
    "            series_block.append(line)\n",
    "\n",
    "    if current_series is not None:\n",
    "        series_data[current_series] = series_block  # Save the last series block\n",
    "\n",
    "    # Check if the requested series exists\n",
    "    if series_number not in series_data:\n",
    "        raise ValueError(f\"Series #{series_number} not found.\")\n",
    "\n",
    "    # Parse the requested series block into a dictionary\n",
    "    series_info = {}\n",
    "    for line in series_data[series_number]:\n",
    "        if line.strip() == '' or line.strip() == '-----':\n",
    "            continue\n",
    "\n",
    "        key_value = re.match(r\"(.+?) = (.+)\", line)\n",
    "        if key_value:\n",
    "            key, value = key_value.groups()\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "\n",
    "            # Attempt to convert value to appropriate type\n",
    "            if value.lower() in ['true', 'false']:\n",
    "                value = value.lower() == 'true'\n",
    "            elif re.match(r'^-?\\d+$', value):\n",
    "                value = int(value)\n",
    "            elif re.match(r'^-?\\d+\\.\\d+$', value):\n",
    "                value = float(value)\n",
    "\n",
    "            series_info[key] = value\n",
    "\n",
    "    return series_info\n",
    "    \n",
    "def vsi_folder_to_zarr(raw_folder = \"Images_raw\",\n",
    "                                tile_size = 512,\n",
    "                                dtype = np.uint16,\n",
    "                                series = 1,\n",
    "                                zarr_level = 0,\n",
    "                                pyramid_level = 0):\n",
    "    '''\n",
    "    This function takes as input the output of the bioformats2raw conversion of a vsi file (https://github.com/glencoesoftware/bioformats2raw),\n",
    "    which creates a folder in a 'zarr' compatible format\n",
    "    '''\n",
    "    \n",
    "    # Open raw folder as Zarr\n",
    "    store = zarr.open(raw_folder, mode='r+')[str(zarr_level)]\n",
    "\n",
    "    # Access specific level of pyramid (usually top, 0)\n",
    "    raw_zarr = store[str(pyramid_level)]\n",
    "    print(f\"Level 0 shape: {raw_zarr.shape}, chunks: {raw_zarr.chunks}\")\n",
    "\n",
    "    # Convert to Dask    \n",
    "    raw_dask = da.from_zarr(raw_zarr)\n",
    "    \n",
    "    # Open and clean metadata\n",
    "    with open(os.path.join(raw_folder, \"OME\", \"METADATA.ome.xml\"), encoding='utf-8') as f:\n",
    "        xml_text = f.read()\n",
    "\n",
    "    xml_text = xml_text.replace(\"√Ç¬µm\", \"¬µm\")\n",
    "\n",
    "    # Now parse with ome-types\n",
    "    from ome_types import from_xml\n",
    "    ome = from_xml(xml_text)\n",
    "    \n",
    "    pixels = ome.images[0].pixels\n",
    "    size_z, size_c, size_y, size_x = pixels.size_z, pixels.size_c, pixels.size_y, pixels.size_x\n",
    "\n",
    "\n",
    "def subtract_background(array, methods, verbose=True):\n",
    "    \"\"\"\n",
    "    Apply background subtraction/enhancement to a Dask or NumPy (C,Y,X) array.\n",
    "    Methods is a list of dicts with:\n",
    "      - 'method': one of rolling_ball, median, morph_opening, clahe, rescale, threshold\n",
    "      - parameters: sigma_px, size_px, rescale (bool), in_range, out_range, threshold\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import dask.array as da\n",
    "    from dask_image.ndfilters import gaussian_filter, median_filter\n",
    "    from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "    from skimage.morphology import opening as grey_opening\n",
    "    from scipy import ndimage\n",
    "\n",
    "    is_dask = isinstance(array, da.Array)\n",
    "    result = array\n",
    "    ndim = result.ndim\n",
    "\n",
    "    for step in methods:\n",
    "        m = step[\"method\"]\n",
    "        if verbose:\n",
    "            print(f\"üîß {m} params={step}\")\n",
    "\n",
    "        # Rolling ball / gaussian\n",
    "        if m == \"rolling_ball\":\n",
    "            œÉ = float(step.get(\"sigma_px\", 50))\n",
    "            sigma = (0.0,)*(ndim-2)+(œÉ,œÉ)\n",
    "            fn = gaussian_filter if is_dask else lambda x: ndimage.gaussian_filter(x, sigma=sigma)\n",
    "            \n",
    "            if is_dask:\n",
    "                bg = fn(result, sigma=sigma)\n",
    "            else:\n",
    "                bg = fn(result)\n",
    "                \n",
    "            # signed subtraction\n",
    "            if is_dask:\n",
    "                result = (result.astype('int32') - bg.astype('int32')).clip(0).astype('uint16')\n",
    "            else:\n",
    "                result = np.clip(result.astype('int32')-bg.astype('int32'), 0, None).astype('uint16')\n",
    "            if step.get(\"rescale\", False):\n",
    "                fn2 = lambda b: rescale_intensity(b, in_range='image', out_range='uint16').astype('uint16')\n",
    "                result = result.map_blocks(fn2, dtype='uint16') if is_dask else fn2(result)\n",
    "\n",
    "        # Median\n",
    "        elif m == \"median\":\n",
    "            s = int(step.get(\"size_px\", 50))\n",
    "            size = (1,)*(ndim-2)+(s,s)\n",
    "            fn = median_filter if is_dask else lambda x: ndimage.median_filter(x, size=size)\n",
    "            bg = fn(result)\n",
    "            if is_dask:\n",
    "                result = (result.astype('int32') - bg.astype('int32')).clip(0).astype('uint16')\n",
    "            else:\n",
    "                result = np.clip(result.astype('int32')-bg.astype('int32'), 0, None).astype('uint16')\n",
    "            if step.get(\"rescale\", False):\n",
    "                fn2 = lambda b: rescale_intensity(b, in_range='image', out_range='uint16').astype('uint16')\n",
    "                result = result.map_blocks(fn2, dtype='uint16') if is_dask else fn2(result)\n",
    "\n",
    "        # Morphological opening\n",
    "        elif m == \"morph_opening\":\n",
    "            s = int(step.get(\"size_px\",50))\n",
    "            footprint = np.ones((1,)*(ndim-2)+(s,s))\n",
    "            if is_dask:\n",
    "                result = result.map_blocks(lambda b: grey_opening(b, footprint=footprint), dtype=result.dtype)\n",
    "            else:\n",
    "                result = grey_opening(result, footprint=footprint)\n",
    "\n",
    "        # CLAHE\n",
    "        elif m == \"clahe\":\n",
    "            fn = lambda b: equalize_adapthist(b.astype('float32')).astype('float32')\n",
    "            result = result.map_blocks(fn, dtype='float32') if is_dask else fn(result)\n",
    "\n",
    "        # Rescale\n",
    "        elif m == \"rescale\":\n",
    "            ir = step.get(\"in_range\",(0,65535))\n",
    "            orng = step.get(\"out_range\",'uint16')\n",
    "            fn = lambda b: rescale_intensity(b, in_range=ir, out_range=orng).astype(orng)\n",
    "            result = result.map_blocks(fn, dtype=orng) if is_dask else fn(result)\n",
    "\n",
    "        # Threshold\n",
    "        elif m == \"threshold\":\n",
    "            t = step.get(\"value\",10)\n",
    "            fn = lambda b: np.where(b<t,0,b).astype(b.dtype)\n",
    "            result = result.map_blocks(fn, dtype=result.dtype) if is_dask else fn(result)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method {m}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def napari_tile_inspector(original_dask,\n",
    "                          chunk_size=(1024,1024),\n",
    "                          channel_names=None,\n",
    "                          channel_colors=None):\n",
    "    \"\"\"\n",
    "    Napari tile inspector with:\n",
    "      - Random tile loading\n",
    "      - Background‚Äësub GUI with parameter widgets\n",
    "      - Sync contrast button (union/intersection)\n",
    "      - Clear adjusted toggle\n",
    "      - Channel color defaults\n",
    "    \"\"\"\n",
    "    C = original_dask.shape[1]\n",
    "    Y = original_dask.shape[3]\n",
    "    X = original_dask.shape[4]\n",
    "    ch_names = channel_names or [f\"Ch{i+1}\" for i in range(C)]\n",
    "    ch_colors = channel_colors or [\"gray\"]*C\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "    raw_layers = []\n",
    "    adjusted_names = []\n",
    "    contrast_limits = []\n",
    "\n",
    "    # Add raw placeholders\n",
    "    for c,name in enumerate(ch_names):\n",
    "        layer = viewer.add_image(\n",
    "            np.zeros(chunk_size),\n",
    "            name=f\"Original - {name}\",\n",
    "            colormap=ch_colors[c],\n",
    "            blending='additive'\n",
    "        )\n",
    "        raw_layers.append(layer)\n",
    "\n",
    "    def load_random(clear_adjusted=False):\n",
    "        # optional clearing\n",
    "        if clear_adjusted:\n",
    "            for nm in adjusted_names:\n",
    "                if nm in viewer.layers:\n",
    "                    viewer.layers.remove(nm)\n",
    "            adjusted_names.clear()\n",
    "\n",
    "        yidx = random.randrange(Y//chunk_size[0])\n",
    "        xidx = random.randrange(X//chunk_size[1])\n",
    "        ys, xs = yidx*chunk_size[0], xidx*chunk_size[1]\n",
    "\n",
    "        for c in range(C):\n",
    "            tile = original_dask[0,c,0,ys:ys+chunk_size[0], xs:xs+chunk_size[1]].compute()\n",
    "            tile = tile.astype(np.uint16)\n",
    "            raw_layers[c].data = tile\n",
    "\n",
    "            # auto contrast\n",
    "            if tile.max()>0:\n",
    "                vmin = np.percentile(tile,1)\n",
    "                vmax = np.percentile(tile,99.5)\n",
    "            else:\n",
    "                vmin,vmax = 0,1\n",
    "            raw_layers[c].contrast_limits = (vmin,vmax)\n",
    "            if len(contrast_limits)<=c:\n",
    "                contrast_limits.append((vmin,vmax))\n",
    "            else:\n",
    "                contrast_limits[c]=(vmin,vmax)\n",
    "\n",
    "    # Random + clear toggle\n",
    "    @magicgui(call_button=\"Random Tile\", clear_adjusted={\"label\": \"Clear adjusted\"})\n",
    "    def btn_random(clear_adjusted: bool = True):\n",
    "        load_random(clear_adjusted)\n",
    "    viewer.window.add_dock_widget(btn_random, area='left', name=\"Tile Controls\")\n",
    "\n",
    "    # Sync contrast helper\n",
    "    def sync_contrast(strategy):\n",
    "        groups = defaultdict(list)\n",
    "        for layer in viewer.layers:\n",
    "            if \" - \" in layer.name:\n",
    "                base = layer.name.split(\" - \",1)[1]\n",
    "                groups[base].append(layer)\n",
    "        for base, layers in groups.items():\n",
    "            vmins = [l.contrast_limits[0] for l in layers]\n",
    "            vmaxs = [l.contrast_limits[1] for l in layers]\n",
    "            if strategy==\"union\":\n",
    "                cl = (min(vmins), max(vmaxs))\n",
    "            else:\n",
    "                cl = (max(vmins), min(vmaxs))\n",
    "            for l in layers:\n",
    "                l.contrast_limits = cl\n",
    "\n",
    "    @magicgui(strategy={\"choices\":[\"union\",\"intersection\"]}, call_button=\"Sync Contrast\")\n",
    "    def btn_sync(strategy: str):\n",
    "        sync_contrast(strategy)\n",
    "    viewer.window.add_dock_widget(btn_sync, area='right', name=\"Contrast Sync\")\n",
    "\n",
    "    # Background GUI\n",
    "    @magicgui(\n",
    "      sigma_px={\"label\":\"Sigma (px)\", \"min\":1, \"max\":500, \"step\":1, \"value\":50},\n",
    "      size_px={\"label\":\"Size (px)\", \"min\":1, \"max\":500, \"step\":1, \"value\":50},\n",
    "      rescale={\"label\":\"Rescale\",\"value\":False},\n",
    "      threshold={\"label\":\"Thresh\",\"min\":0,\"max\":1000,\"step\":1,\"value\":10},\n",
    "      method={\"choices\":[\"rolling_ball\",\"median\",\"morph_opening\",\"clahe\",\"rescale\",\"threshold\"]},\n",
    "      call_button=\"Apply\"\n",
    "    )\n",
    "    def apply_bg(method:str, sigma_px:int, size_px:int, rescale:bool, threshold:int):\n",
    "        try:\n",
    "            for c,name in enumerate(ch_names):\n",
    "                tile = raw_layers[c].data\n",
    "                if tile is None: continue\n",
    "                arr = tile[None,...]\n",
    "                params = {\"method\":method}\n",
    "                if method in (\"rolling_ball\",\"median\"):\n",
    "                    params[\"sigma_px\" if method==\"rolling_ball\" else \"size_px\"] = sigma_px if method==\"rolling_ball\" else size_px\n",
    "                    if rescale: params[\"rescale\"]=True\n",
    "                if method==\"threshold\": params[\"value\"]=threshold\n",
    "                if method==\"rescale\": params={\"method\":\"rescale\",\"in_range\":(0,65535),\"out_range\":\"uint16\"}\n",
    "\n",
    "                corrected = subtract_background(arr, [params], verbose=False)\n",
    "                if isinstance(corrected, da.Array):\n",
    "                    corrected=corrected.compute()\n",
    "                corrected=np.squeeze(corrected)\n",
    "                if corrected.ndim!=2: continue\n",
    "\n",
    "                cl = contrast_limits[c]\n",
    "                nm = f\"{method} - {name}\"\n",
    "                # safe add\n",
    "                def make_do_add(data, nm, cmap, clims):\n",
    "                    def _add():\n",
    "                        try:\n",
    "                            viewer.add_image(data, name=nm,\n",
    "                                             colormap=cmap,\n",
    "                                             blending='additive',\n",
    "                                             contrast_limits=clims)\n",
    "                            adjusted_names.append(nm)\n",
    "                        except Exception as e:\n",
    "                            show_error(str(e))\n",
    "                    return _add\n",
    "\n",
    "                QTimer.singleShot(0, make_do_add(corrected, nm, ch_colors[c], cl))\n",
    "                \n",
    "            show_info(\"Applied \"+method)\n",
    "        except Exception as e:\n",
    "            show_error(str(e))\n",
    "\n",
    "    viewer.window.add_dock_widget(apply_bg, area='right', name=\"Bg Subtraction\")\n",
    "\n",
    "    @magicgui(call_button=\"Save Snapshot\")\n",
    "    def save_snap():\n",
    "        try:\n",
    "            combo = [raw_layers[c].data for c in range(C)]\n",
    "            arr = np.stack(combo,axis=0)\n",
    "            fn=f\"tile_{random.randint(0,9999)}.tif\"\n",
    "            imsave(fn,arr.astype('uint16'))\n",
    "            show_info(\"Saved \"+fn)\n",
    "        except Exception as e:\n",
    "            show_error(str(e))\n",
    "    viewer.window.add_dock_widget(save_snap, area='right', name=\"Export\")\n",
    "\n",
    "    load_random(clear_adjusted=True)\n",
    "    return viewer\n",
    "\n",
    "\n",
    "def build_pyramid_numpy(base, num_levels):\n",
    "    \"\"\"Build a pyramid using skimage downscale on NumPy array.\"\"\"\n",
    "    pyramid = [base]\n",
    "    for _ in range(1, num_levels):\n",
    "        base = downscale_local_mean(base, (1, 1, 1, 2, 2)).astype(base.dtype)\n",
    "        pyramid.append(base)\n",
    "    return pyramid\n",
    "\n",
    "def build_pyramid_dask(base, num_levels):\n",
    "    \"\"\"Build a pyramid using Dask coarsen on Dask array.\"\"\"\n",
    "    pyramid = [base]\n",
    "    for _ in range(1, num_levels):\n",
    "        base = da.coarsen(np.mean, base, {3: 2, 4: 2}, trim_excess=True)\n",
    "        pyramid.append(base)\n",
    "    return pyramid\n",
    "\n",
    "def save_modified_zarr_pyramid(zarr_path, zarr_level=\"0\", methods=None, load_into_memory=False):\n",
    "    \"\"\"\n",
    "    Optimized background subtraction + pyramid overwrite for Zarr arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - zarr_path (str): Path to root Zarr directory\n",
    "    - zarr_level (str): Subgroup under which pyramid arrays exist (e.g. \"0\")\n",
    "    - methods (list): Background subtraction steps (passed to subtract_background)\n",
    "    - load_into_memory (bool): Whether to load level 0 fully into RAM (recommended if fits)\n",
    "    \"\"\"\n",
    "    if methods is None:\n",
    "        raise ValueError(\"Must provide background subtraction methods.\")\n",
    "\n",
    "    # Open level group\n",
    "    zgroup = zarr.open(zarr_path, mode=\"r+\")[zarr_level]\n",
    "    level_keys = sorted(k for k in zgroup.array_keys() if k.isdigit())\n",
    "    num_levels = len(level_keys)\n",
    "\n",
    "    print(f\"üìÇ Found {num_levels} pyramid arrays in: {zarr_path}/{zarr_level}/\")\n",
    "\n",
    "    # Load level 0\n",
    "    level0_key = level_keys[0]\n",
    "    level0_dask = da.from_zarr(zgroup[level0_key])\n",
    "    print(f\"üìè Level 0 shape: {level0_dask.shape}, dtype: {level0_dask.dtype}\")\n",
    "\n",
    "    # === Apply background subtraction ===\n",
    "    if load_into_memory:\n",
    "        print(\"üß† Loading full-resolution level 0 into memory...\")\n",
    "        level0_np = level0_dask.compute()\n",
    "        corrected = subtract_background(level0_np, methods=methods)\n",
    "        pyramid = build_pyramid_numpy(corrected, num_levels)\n",
    "        for i, level in enumerate(pyramid):\n",
    "            print(f\"üíæ Writing NumPy level {i}\")\n",
    "            da.from_array(level, chunks=level.shape).to_zarr(zgroup[str(i)], overwrite=True)\n",
    "    else:\n",
    "        print(\"üê¢ Using Dask (lazy, more memory efficient)...\")\n",
    "        corrected = subtract_background(level0_dask, methods=methods).persist()\n",
    "        base = corrected\n",
    "        for i in range(num_levels):\n",
    "            print(f\"üíæ Writing Dask level {i}\")\n",
    "            base.to_zarr(zgroup[str(i)], overwrite=True)\n",
    "            base = da.coarsen(np.mean, base, {3: 2, 4: 2}, trim_excess=True)\n",
    "\n",
    "    print(\"‚úÖ Zarr pyramid update complete.\")\n",
    "    \n",
    "def vsi_background_subtract(vsi_path, \n",
    "                            raw_folder,\n",
    "                            output_ometiff = 'pyramid_output.ome.tiff',\n",
    "                            methods = [{\"method\": \"rolling_ball\", \"sigma_px\": 50}],\n",
    "                            vsi_series=2, # For Olympus V200 fluorescent, this should be 2\n",
    "                            zarr_level=\"0\", # For Olympus V200 fluorescent, this should be \"0\"\n",
    "                            max_workers=8, # For Java\n",
    "                            load_into_memory=False, # Whether or not to load the entire 0 resolution file into memory. Faster, but requires loads of RAM!\n",
    "                            overwrite=True,\n",
    "                            patch_size=512):\n",
    "    \n",
    "    # Extract metadata using showinf, including resolutions\n",
    "    print(f\"Using showinf to read metadata for {vsi_path}, series# {vsi_series}...\\n\")\n",
    "    showinf_readout = run_commandline(f\"showinf -nopix -noflat -series {vsi_series} {vsi_path}\", verbose=1, return_readout=True)\n",
    "    \n",
    "    # Extract metadata to dictionary\n",
    "    series_metadata = parse_showinf_series_metadata(showinf_readout, series_number=vsi_series)\n",
    "\n",
    "    print(f'Metadata for {vsi_path}, series# {vsi_series}:')\n",
    "    for i,v in series_metadata.items():\n",
    "        print(f\"{i} = {v}\")\n",
    "        \n",
    "    # If folder exists, then must have overwrite enabld\n",
    "    if not os.path.isdir(raw_folder) or overwrite:\n",
    "        print('\\nConverting .vsi whole slide image files into zarr folder...')\n",
    "        # Covert VSI to zarr-comptaible folder using 'bioformats2raw' java program\n",
    "        run_commandline(f\"bioformats2raw --overwrite --resolutions {series_metadata['Resolutions']} --tile-width {patch_size} --max-workers {max_workers} --series {vsi_series} {vsi_path} {raw_folder}\", verbose=1, print_command=True)\n",
    "    else:\n",
    "        print(f'\\nExisting raw folder found at {raw_folder}, skipping extraction (select overwrite=True to overwrite existing folder)')\n",
    "    \n",
    "    # Update the zarr folder after performin the background subtraction method\n",
    "    save_modified_zarr_pyramid(raw_folder, zarr_level=zarr_level, methods=methods, load_into_memory=load_into_memory)\n",
    "    \n",
    "    # Covert zarr-comptaible folder using 'raw2ometiff' java program back into\n",
    "    run_commandline(f\"raw2ometiff {raw_folder} {output_ometiff}\", verbose=1, print_command=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3731f9-182a-43ea-a0b7-7bd0e80e5cc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Viewer (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e19207-0d48-4580-96c1-efd285747594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from magicgui import magicgui\n",
    "import random\n",
    "from skimage.io import imsave\n",
    "\n",
    "def napari_tile_viewer_fixed(original_dask, \n",
    "                             corrected_dask, \n",
    "                             chunk_size=(256, 256), \n",
    "                             channel_names=None, \n",
    "                             threshold=0, \n",
    "                             smart_scan=True):\n",
    "    \"\"\"\n",
    "    Tile viewer that shows original & corrected tiles, with optional non-empty tile filtering.\n",
    "    Includes snapshot saving.\n",
    "    \n",
    "    Params:\n",
    "    - smart_scan: if True, only shows tiles with data > threshold.\n",
    "                  if False, randomly picks tiles without checking.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correct shape indexing\n",
    "    C = original_dask.shape[1]  # Channels\n",
    "    Y = original_dask.shape[3]  # Y axis\n",
    "    X = original_dask.shape[4]  # X axis\n",
    "\n",
    "    chunk_h, chunk_w = chunk_size\n",
    "\n",
    "    if channel_names is None:\n",
    "        channel_names = [f\"Channel {i+1}\" for i in range(C)]\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Placeholder layers\n",
    "    orig_layers = []\n",
    "    corr_layers = []\n",
    "\n",
    "    for c in range(C):\n",
    "        orig_layer = viewer.add_image(\n",
    "            np.zeros(chunk_size),\n",
    "            name=f\"Original - {channel_names[c]}\",\n",
    "            colormap='gray',\n",
    "            blending='additive'\n",
    "        )\n",
    "        corr_layer = viewer.add_image(\n",
    "            np.zeros(chunk_size),\n",
    "            name=f\"Corrected - {channel_names[c]}\",\n",
    "            colormap='magma',\n",
    "            blending='additive',\n",
    "            visible=False\n",
    "        )\n",
    "        orig_layers.append(orig_layer)\n",
    "        corr_layers.append(corr_layer)\n",
    "\n",
    "    # Tile grid size\n",
    "    y_tiles = Y // chunk_h\n",
    "    x_tiles = X // chunk_w\n",
    "\n",
    "    # Smart scan mode: build list of valid tiles\n",
    "    if smart_scan:\n",
    "        print(\"üîé Scanning for non-empty tiles...\")\n",
    "\n",
    "        valid_tiles = []\n",
    "        for y_idx in range(y_tiles):\n",
    "            for x_idx in range(x_tiles):\n",
    "                y_start = y_idx * chunk_h\n",
    "                x_start = x_idx * chunk_w\n",
    "\n",
    "                tile = original_dask[0, :, 0, y_start:y_start+chunk_h, x_start:x_start+chunk_w]\n",
    "                tile_max = tile.max().compute()\n",
    "\n",
    "                if tile_max > threshold:\n",
    "                    valid_tiles.append((y_idx, x_idx))\n",
    "\n",
    "        print(f\"‚úÖ Found {len(valid_tiles)} valid tiles with signal > {threshold}\")\n",
    "\n",
    "        if not valid_tiles:\n",
    "            print(\"‚ö†Ô∏è No valid tiles found. Switching to random mode.\")\n",
    "            smart_scan = False\n",
    "\n",
    "    # Load tile by coordinates\n",
    "    def load_tile(y_idx, x_idx):\n",
    "        y_start = y_idx * chunk_h\n",
    "        x_start = x_idx * chunk_w\n",
    "\n",
    "        for c in range(C):\n",
    "            orig_tile = original_dask[0, c, 0, y_start:y_start+chunk_h, x_start:x_start+chunk_w].compute()\n",
    "            corr_tile = corrected_dask[0, c, 0, y_start:y_start+chunk_h, x_start:x_start+chunk_w].compute()\n",
    "\n",
    "            orig_layers[c].data = orig_tile\n",
    "            corr_layers[c].data = corr_tile\n",
    "\n",
    "        print(f\"üì¶ Loaded tile Y: {y_idx}, X: {x_idx}\")\n",
    "\n",
    "    # Random tile loader\n",
    "    def load_random_tile():\n",
    "        if smart_scan:\n",
    "            y_idx, x_idx = random.choice(valid_tiles)\n",
    "        else:\n",
    "            y_idx = random.randint(0, y_tiles - 1)\n",
    "            x_idx = random.randint(0, x_tiles - 1)\n",
    "        load_tile(y_idx, x_idx)\n",
    "\n",
    "    # Randomize button\n",
    "    @magicgui(call_button='Random Tile')\n",
    "    def randomize_tile():\n",
    "        load_random_tile()\n",
    "\n",
    "    viewer.window.add_dock_widget(randomize_tile, area='left', name='Tile Controls')\n",
    "\n",
    "    # Snapshot button\n",
    "    @magicgui(call_button='Save Snapshot')\n",
    "    def save_snapshot():\n",
    "        combined = []\n",
    "        for c in range(C):\n",
    "            orig_data = orig_layers[c].data\n",
    "            corr_data = corr_layers[c].data\n",
    "            combined.append(np.concatenate((orig_data, corr_data), axis=1))  # side by side\n",
    "\n",
    "        snapshot = np.stack(combined, axis=0)\n",
    "        filename = f\"tile_snapshot_{random.randint(1000,9999)}.tif\"\n",
    "        imsave(filename, snapshot.astype('uint16'))\n",
    "        print(f\"üíæ Snapshot saved: {filename}\")\n",
    "\n",
    "    viewer.window.add_dock_widget(save_snapshot, area='left', name='Export Snapshot')\n",
    "\n",
    "    # Load initial tile\n",
    "    load_random_tile()\n",
    "\n",
    "    print(f\"‚úÖ Tile viewer ready. Mode: {'Smart Scan' if smart_scan else 'Random'}\")\n",
    "    return viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf635f-8893-429b-94f5-63874330933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Dask array shape:\", level0_dask.shape)\n",
    "print(\"Dask dtype:\", level0_dask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff4076-5ca5-498b-92c3-2d513e640131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick random mode (no scan)\n",
    "napari_tile_viewer_fixed(level0_dask, corrected, chunk_size=(1024, 1024), channel_names=[\"DAPI\", \"FITC\"], smart_scan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f78a2a-9268-4203-96cd-45ed4fa0c54e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Non-pyramid napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e86b5-0fd4-49b1-ae2a-23a2616f46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from qtpy.QtWidgets import QApplication\n",
    "\n",
    "def napari_compare_original_corrected(original_dask, corrected_dask, channel_names=None):\n",
    "    def squeeze_display(arr):\n",
    "        arr = da.squeeze(arr)\n",
    "        if arr.ndim == 2:\n",
    "            arr = arr[None, ...]\n",
    "        return arr\n",
    "\n",
    "    orig = squeeze_display(original_dask)\n",
    "    corr = squeeze_display(corrected_dask)\n",
    "\n",
    "    n_channels = orig.shape[0]\n",
    "\n",
    "    if channel_names is None:\n",
    "        channel_names = [f\"Channel {i+1}\" for i in range(n_channels)]\n",
    "\n",
    "    # Ensure QApplication exists\n",
    "    # app = QApplication.instance() or QApplication([])\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        viewer.add_image(\n",
    "            orig[i],\n",
    "            name=f\"Original - {channel_names[i]}\",\n",
    "            colormap='gray',\n",
    "            blending='additive'\n",
    "        )\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        viewer.add_image(\n",
    "            corr[i],\n",
    "            name=f\"Corrected - {channel_names[i]}\",\n",
    "            colormap='magma',\n",
    "            blending='additive',\n",
    "            visible=False\n",
    "        )\n",
    "\n",
    "    print(f\"‚úÖ Napari launched with {n_channels} channels.\")\n",
    "\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86278abf-6475-4a17-b4b1-0c870a3b554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari_compare_original_corrected(level0_dask, corrected, channel_names=[\"DAPI\", \"FITC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2fc1e-90bd-4c14-a059-6024cdde99c2",
   "metadata": {},
   "source": [
    "### Overwrite in Zarr Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeeb744-5d9d-45b5-9a61-dceb87fe2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back into level 0 (in-place)\n",
    "processed.to_zarr(store['0']['0'], overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442bc10-f495-4dd8-a1cc-6e14862f962b",
   "metadata": {},
   "source": [
    "### Rebuild Pyramid Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436667f4-442e-4791-9832-004e560c8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import downscale_local_mean\n",
    "\n",
    "def rebuild_pyramid_level(src_dask, level_num, downscale_factor):\n",
    "    downscaled = src_dask.map_blocks(\n",
    "        lambda block: downscale_local_mean(block, (1, downscale_factor, downscale_factor)),\n",
    "        dtype=src_dask.dtype\n",
    "    )\n",
    "    # Write to Zarr group for pyramid level\n",
    "    grp = store.require_group(str(level_num))\n",
    "    downscaled.to_zarr(grp.require_dataset('0', shape=downscaled.shape, dtype=downscaled.dtype, chunks=downscaled.chunks), overwrite=True)\n",
    "\n",
    "# Example pyramid levels\n",
    "rebuild_pyramid_level(processed, 1, 2)  # Level 1 (2x downsampled)\n",
    "rebuild_pyramid_level(processed, 2, 4)  # Level 2 (4x downsampled)\n",
    "rebuild_pyramid_level(processed, 3, 8)  # Level 3 (8x downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930195b-e10a-491d-ba2d-5e3921d7c867",
   "metadata": {},
   "source": [
    "### Multi-scale compare (too slow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336029d4-fd0f-497d-bb20-a18857ad8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import dask.array as da\n",
    "\n",
    "def napari_multiscale_compare(original_pyramid, corrected_pyramid, channel_names=None):\n",
    "    \"\"\"\n",
    "    Compare original & corrected pyramidal WSIs in Napari (multiscale mode).\n",
    "\n",
    "    Parameters:\n",
    "    - original_pyramid: List of Dask arrays (level0, level1, level2, ...)\n",
    "    - corrected_pyramid: Same as above, processed version\n",
    "    - channel_names: List of channel names (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure input is list of levels\n",
    "    assert isinstance(original_pyramid, list), \"original_pyramid must be a list of Dask arrays\"\n",
    "    assert isinstance(corrected_pyramid, list), \"corrected_pyramid must be a list of Dask arrays\"\n",
    "    assert len(original_pyramid) == len(corrected_pyramid), \"Pyramid levels must match\"\n",
    "\n",
    "    # Get number of channels from level 0\n",
    "    n_channels = original_pyramid[0].shape[0]\n",
    "    if channel_names is None:\n",
    "        channel_names = [f\"Channel {i+1}\" for i in range(n_channels)]\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add original channels as multiscale layers\n",
    "    for c in range(n_channels):\n",
    "        orig_levels = [level[c] for level in original_pyramid]\n",
    "        viewer.add_image(\n",
    "            orig_levels,\n",
    "            name=f\"Original - {channel_names[c]}\",\n",
    "            colormap='gray',\n",
    "            blending='additive',\n",
    "            multiscale=True\n",
    "        )\n",
    "\n",
    "    # Add corrected channels as multiscale layers (hidden by default)\n",
    "    for c in range(n_channels):\n",
    "        corr_levels = [level[c] for level in corrected_pyramid]\n",
    "        viewer.add_image(\n",
    "            corr_levels,\n",
    "            name=f\"Corrected - {channel_names[c]}\",\n",
    "            colormap='magma',\n",
    "            blending='additive',\n",
    "            multiscale=True,\n",
    "            visible=False\n",
    "        )\n",
    "\n",
    "    print(f\"‚úÖ Multiscale Napari viewer with {n_channels} channels loaded.\")\n",
    "    return viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b014e-451a-4ffc-af28-7fc8db303079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming level0_dask and corrected are (T, C, Z, Y, X) or (C, Y, X)\n",
    "raw_pyramid = build_pyramid(level0_dask, num_levels=7)\n",
    "corrected_pyramid = build_pyramid(corrected, num_levels=7)\n",
    "\n",
    "# Now you can feed these into the multiscale viewer\n",
    "viewer = napari_multiscale_compare(raw_pyramid, corrected_pyramid, channel_names=[\"DAPI\", \"FITC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829258e5-04fd-4607-bd44-7e904a57c8de",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fe351-339b-49fb-9f52-8a2561f2c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(dask_array, methods, verbose=True):\n",
    "    \"\"\"\n",
    "    Apply background subtraction methods to a Dask array.\n",
    "\n",
    "    Parameters:\n",
    "    - dask_array: Dask array (e.g., shape (T, C, Z, Y, X))\n",
    "    - methods: list of dicts, each specifying method and parameters.\n",
    "    \"\"\"\n",
    "    ndim = dask_array.ndim\n",
    "    result = dask_array\n",
    "\n",
    "    for step in methods:\n",
    "        method = step[\"method\"]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Applying: {method} with params {step}\")\n",
    "\n",
    "        if method == \"rolling_ball\":\n",
    "            sigma_px = step.get(\"sigma_px\", 100)\n",
    "            sigma = (0.0,) * (ndim - 2) + (float(sigma_px), float(sigma_px))\n",
    "            background = gaussian_filter(result, sigma=sigma)\n",
    "            result = result - background\n",
    "            result = da.clip(result, 0, None)\n",
    "\n",
    "        elif method == \"morph_opening\":\n",
    "            size_px = step.get(\"size_px\", 100)\n",
    "            size = (1,) * (ndim - 2) + (size_px, size_px)\n",
    "\n",
    "            def morph_opening_block(block):\n",
    "                return grey_opening(block, size=size)\n",
    "\n",
    "            result = result.map_blocks(morph_opening_block, dtype=result.dtype)\n",
    "\n",
    "\n",
    "        elif method == \"median\":\n",
    "            size_px = step.get(\"size_px\", 100)\n",
    "            size = (1,) * (ndim - 2) + (size_px, size_px)\n",
    "            background = median_filter(result, size=size)\n",
    "            result = result - background\n",
    "            result = da.clip(result, 0, None)\n",
    "\n",
    "            # Rescale back to data range for visualization\n",
    "            dtype_out = result.dtype\n",
    "            def rescale_block(block):\n",
    "                return rescale_intensity(block, in_range='image', out_range='uint16').astype('uint16')\n",
    "\n",
    "            result = result.map_blocks(rescale_block, dtype='uint16')\n",
    "\n",
    "        elif method == \"clahe\":\n",
    "            def clahe_block(block):\n",
    "                return equalize_adapthist(block.astype('float32')).astype('float32')\n",
    "            \n",
    "            result = result.map_blocks(clahe_block, dtype='float32')\n",
    "\n",
    "        elif method == \"rescale\":\n",
    "            in_range = step.get(\"in_range\", (0, 65535))\n",
    "            out_range = step.get(\"out_range\", 'uint16')\n",
    "\n",
    "            def rescale_block(block):\n",
    "                return rescale_intensity(block, in_range=in_range, out_range=out_range).astype(out_range)\n",
    "\n",
    "            result = result.map_blocks(rescale_block, dtype=out_range)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495128d8-a461-449f-ae4f-9e5ca58c195f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Dask monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9cbe1-ff7d-4f6d-a402-d01399b60382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Start Dask cluster\n",
    "cluster = LocalCluster(n_workers=6, threads_per_worker=2, memory_limit='12GB')\n",
    "client = Client(cluster)\n",
    "\n",
    "print(client)\n",
    "\n",
    "# http://localhost:8787/status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sbt]",
   "language": "python",
   "name": "conda-env-sbt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
